<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> research | PAIR </title> <meta name="author" content="PAIR Lab"> <meta name="description" content="PAIR research thrusts"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/al-folio/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/al-folio/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/al-folio/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%99%BE%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/al-folio/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pairlab.github.io/al-folio/research/"> <script src="/al-folio/assets/js/theme.js?d25c4b117d08504ee8ffd95485db4720"></script> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/al-folio/"> <img alt="PAIR Logo" src="https://pairlab.github.io/al-folio/assets/img/pair-logo-2-bw.png" height="40" style="margin-top:5px"> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/al-folio/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/al-folio/research/">research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/people/">people </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/contact/">contact </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/blog/">blog </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/al-folio/teaching/">courses</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/news/">news archive</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/media/">press &amp; media</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/resources/">code &amp; talks</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://animesh.garg.tech/" rel="external nofollow noopener" target="_blank">Animesh Garg</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-3" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">research</h1> <p class="post-description">PAIR research thrusts</p> </header> <article> <p>We aim to build algorithms for perceptual representations learned by and for interaction, causal understanding of mechanisms, and physically-grounded reasoning in practical settings. An emblematic north star is to enable an autonomous robot to watch an instructional video, or a set of these videos, and then learn a policy to execute the task in a new setting. We build both algorithms and systems that have a broad range of applications in different domains in robot autonomy. PAIR group blends ideas in <em>Causality</em>, <em>Perception</em>, and <em>Reinforcement Learning</em> towards this vision.</p> <p>As a group we pride ourselves on building and applying learning algorithms on different real robot platforms.</p> <div class="row mt-3 align-items-center justify-content-around"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-planning-robot1-small-480.webp 480w,/al-folio/assets/img/res-planning-robot1-small-800.webp 800w,/al-folio/assets/img/res-planning-robot1-small-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-planning-robot1-small.gif" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-cavin-480.webp 480w,/al-folio/assets/img/res-cavin-800.webp 800w,/al-folio/assets/img/res-cavin-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-cavin.gif" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-multimodal-test-480.webp 480w,/al-folio/assets/img/res-multimodal-test-800.webp 800w,/al-folio/assets/img/res-multimodal-test-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-multimodal-test.gif" class="rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Personal &amp; Service Robotics </div> <div class="row mt-3 align-items-center justify-content-around"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-cutting-480.webp 480w,/al-folio/assets/img/res-cutting-800.webp 800w,/al-folio/assets/img/res-cutting-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-cutting.gif" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-suturing-480.webp 480w,/al-folio/assets/img/res-suturing-800.webp 800w,/al-folio/assets/img/res-suturing-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-suturing.gif" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-acubot-480.webp 480w,/al-folio/assets/img/res-acubot-800.webp 800w,/al-folio/assets/img/res-acubot-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-acubot.gif" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Surgical &amp; Healthcare Robotics </div> <div class="row mt-3 align-items-center justify-content-around"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-laikago-skateboard-480.webp 480w,/al-folio/assets/img/res-laikago-skateboard-800.webp 800w,/al-folio/assets/img/res-laikago-skateboard-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-laikago-skateboard.gif" class="img-fluid rounded z-depth-1 " width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-laikago-dr-480.webp 480w,/al-folio/assets/img/res-laikago-dr-800.webp 800w,/al-folio/assets/img/res-laikago-dr-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-laikago-dr.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-laikago-kick-480.webp 480w,/al-folio/assets/img/res-laikago-kick-800.webp 800w,/al-folio/assets/img/res-laikago-kick-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-laikago-kick.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Locomanipulation </div> <h3 id="1-generalizable-representations-in-rl-for-robotics">1. Generalizable Representations in RL for Robotics</h3> <p>A key focus of our work is to understand the role of representations in RL towards efficiency and generalization in skill acquisition. RL is mainly composed of State Space (Input), Action space (Output), a Learning Rule, and Policy (or value) model.</p> <p>Structured biases upend contemporary methods in all four dimensions, pointing to a need for deeper analysis of representations in RL.</p> <ul> <li>States: <a href="http://arxiv.org/abs/2001.09518" rel="external nofollow noopener" target="_blank">Unsupervised Keypoints</a>, <a href="https://sites.google.com/view/visionandtouch" rel="external nofollow noopener" target="_blank">Making Sense of Touch and Vision</a> </li> <li>Objects Representations: <a href="https://sites.google.com/view/task-oriented-grasp" rel="external nofollow noopener" target="_blank">Task Oriented Grasping</a>, <a href="https://sites.google.com/view/task-oriented-grasp" rel="external nofollow noopener" target="_blank">Affordance for Tool-Use</a> </li> <li>Actions: <a href="https://arxiv.org/abs/1906.08880" rel="external nofollow noopener" target="_blank">VICES</a>, <a href="https://www.pair.toronto.edu/laser" rel="external nofollow noopener" target="_blank">LASER</a>, <a href="https://sites.google.com/view/centroidal-rl" rel="external nofollow noopener" target="_blank">GliDE</a> </li> <li>Algorithms: <a href="https://arxiv.org/abs/2011.12363" rel="external nofollow noopener" target="_blank">C-Learning</a>, <a href="http://arxiv.org/abs/2005.10934" rel="external nofollow noopener" target="_blank">LEAF</a>, <a href="http://arxiv.org/abs/2008.07087" rel="external nofollow noopener" target="_blank">OCEAN</a> </li> <li>Architectures: <a href="https://sites.google.com/view/d2rl/home" rel="external nofollow noopener" target="_blank">Deep-Dense nets in RL</a> </li> </ul> <div class="row mt-3 justify-content-around align-items-center"> <div class="col-sm-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-tog-480.webp 480w,/al-folio/assets/img/res-tog-800.webp 800w,/al-folio/assets/img/res-tog-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-tog.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-laser-intro-480.webp 480w,/al-folio/assets/img/res-laser-intro-800.webp 800w,/al-folio/assets/img/res-laser-intro-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-laser-intro.jpg" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-5 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-clearning-480.webp 480w,/al-folio/assets/img/res-clearning-800.webp 800w,/al-folio/assets/img/res-clearning-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-clearning.gif" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>3D Vision: Object and Scene representations for manipulation.</li> <li>Perceptual Concept Learning</li> <li>Geomteric Deep Learning for discovery of symmetries</li> </ul> <h3 id="2-causal-discovery-and-inference-in-robotics">2. Causal Discovery and Inference in Robotics</h3> <p>Causal understanding is one of key pillars of my current and future agenda. A simulator is a generative world model, and similarly follows a system of structural mechanisms. However, model learning focuses solely on statistical dependence, while Causal Models go beyond it to build representations that support intervention, planning, and modular reasoning. These methods provide a concrete step towards bridging vision and robotics through sub-goal inference and counterfactual imagination.</p> <div class="row mt-3 justify-content-around align-items-center"> <div class="col-sm-9 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-vcdn-480.webp 480w,/al-folio/assets/img/res-vcdn-800.webp 800w,/al-folio/assets/img/res-vcdn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-vcdn.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-mac-480.webp 480w,/al-folio/assets/img/res-mac-800.webp 800w,/al-folio/assets/img/res-mac-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-mac.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Disentangled Generative Models: <a href="https://sites.google.com/nvidia.com/semi-stylegan" rel="external nofollow noopener" target="_blank">Semi-Supervised StyleGAN</a>, <a href="https://github.com/NVIDIA/UnsupervisedLandmarkLearning" rel="external nofollow noopener" target="_blank">Unsupervised Keypoints</a> </li> <li>Causal Factor Graphs: <a href="https://yunzhuli.github.io/V-CDN/" rel="external nofollow noopener" target="_blank">Visual Causal Discovery</a> </li> <li>Instruction Guided Counterfactual Generation: <a href="https://iccv-mac.github.io/MAC/" rel="external nofollow noopener" target="_blank">Action Concepts</a> </li> </ul> <h3 id="3-crowd-scale-robot-learning-with-imitationofflinebatch-rl">3. Crowd-Scale Robot Learning with Imitation/Offline/Batch RL</h3> <p>Data-driven methods help RL in exploration and reward specification. Robot learning, however, is limited by modest-sized real data. Access to data brings new algorithmic opportunities to robotics, as it did in vision and language. However, it also poses challenges due to static nature of data and covariate shifts.</p> <div class="row mt-3 align-items-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-rt-alps-480.webp 480w,/al-folio/assets/img/res-rt-alps-800.webp 800w,/al-folio/assets/img/res-rt-alps-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-rt-alps.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-roboturk-480.webp 480w,/al-folio/assets/img/res-roboturk-800.webp 800w,/al-folio/assets/img/res-roboturk-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-roboturk.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-coda-480.webp 480w,/al-folio/assets/img/res-coda-800.webp 800w,/al-folio/assets/img/res-coda-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-coda.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Scalable Teleoperation with Roboturk: <a href="http://roboturk.stanford.edu/" rel="external nofollow noopener" target="_blank">Roboturk-v1</a>, <a href="https://roboturk.stanford.edu/realrobotdataset#tasks" rel="external nofollow noopener" target="_blank">Roboturk-v2</a> </li> <li>Imitation Learning: <a href="http://arxiv.org/abs/1909.04121" rel="external nofollow noopener" target="_blank">AC-Teach</a>, <a href="http://arxiv.org/abs/2101.07241" rel="external nofollow noopener" target="_blank">LbW</a>, <a href="http://arxiv.org/abs/1911.05864" rel="external nofollow noopener" target="_blank">Goal-based Imitation</a> </li> <li>Offline/Batch Policy Learning and Causal Data Augmengation: <a href="https://sites.google.com/stanford.edu/iris/" rel="external nofollow noopener" target="_blank">IRIS</a>, <a href="https://arxiv.org/abs/2007.02863" rel="external nofollow noopener" target="_blank">CoDA</a>, <a href="http://arxiv.org/abs/2103.06326" rel="external nofollow noopener" target="_blank">S4RL</a> </li> <li>Safe Transfer to Real Systems: <a href="https://stanfordvl.github.io/ARPL/" rel="external nofollow noopener" target="_blank">Adversarial Policy Learning</a>, <a href="https://arxiv.org/abs/1707.04674" rel="external nofollow noopener" target="_blank">Adaptive Polict Transfer</a>, <a href="https://sites.google.com/view/conservative-safety-critics/home" rel="external nofollow noopener" target="_blank">Conservative Safety Critics</a> </li> </ul> <h3 id="4-structured-biases-for-hierarchical-planning">4. Structured Biases for Hierarchical Planning</h3> <p>Procedural reasoning, such as in robotics, needs both skills and their structured composition for interaction planning towards a higher-order objective. However, manual composition of skills via a finite state-machine design is both tedious and unscalable. Thus the need for inductive bias is intensified for cognitive reasoning. I have developed imitation guided policy learning in abstract spaces for hierarchically structure tasks.</p> <div class="row mt-3 align-items-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/res-ntp-small-480.webp 480w,/al-folio/assets/img/res-ntp-small-800.webp 800w,/al-folio/assets/img/res-ntp-small-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/res-ntp-small.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Neural Planning Modules for One-Shot Imitation: <a href="https://stanfordvl.github.io/ntp/" rel="external nofollow noopener" target="_blank">NTP</a>, <a href="https://arxiv.org/abs/1807.03480" rel="external nofollow noopener" target="_blank">NTG</a>, <a href="https://arxiv.org/abs/1908.06769" rel="external nofollow noopener" target="_blank">Continuous Symbolic Planner</a> </li> <li>Task Structure Representations: <a href="https://www.youtube.com/watch?time_continue=2&amp;v=L561cJh7DLE" rel="external nofollow noopener" target="_blank">Transition State Clustering</a>, <a href="http://berkeleyautomation.github.io/tsc-dl/" rel="external nofollow noopener" target="_blank">TSC-DL</a>, <a href="https://animesh.garg.tech/assets/pdf/garg_swirl_ijrr18.pdf" rel="external nofollow noopener" target="_blank">SWIRL</a> </li> <li>Learning from Videos: <a href="https://finding-it.github.io/" rel="external nofollow noopener" target="_blank">Finding-it</a> </li> <li>Dynamics with Latent Hierarchical Structure: <a href="http://pair.stanford.edu/cavin/" rel="external nofollow noopener" target="_blank">CAVIN</a>, <a href="http://arxiv.org/abs/2011.13897" rel="external nofollow noopener" target="_blank">Skill Hierarchies</a> </li> </ul> <h3 id="5-applications-to-real-robot-systems">5. Applications to Real Robot Systems</h3> <p>The algorithmic ideas have been motivated by problems in mobility and manipulation in robotics, and have been evaluated on various physical robot platforms.</p> <div class="row mt-3 align-items-center justify-content-around"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/real-robots-garg-480.webp 480w,/al-folio/assets/img/real-robots-garg-800.webp 800w,/al-folio/assets/img/real-robots-garg-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/al-folio/assets/img/real-robots-garg.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Personal &amp; Service Robotics: <a href="https://sites.google.com/view/task-oriented-grasp" rel="external nofollow noopener" target="_blank">Tool Use</a>, <a href="https://www.youtube.com/watch?v=OdqJuvAHvGE" rel="external nofollow noopener" target="_blank">Task Planning</a>, <a href="https://www.youtube.com/watch?v=NwMukXa8kys&amp;feature=youtu.be" rel="external nofollow noopener" target="_blank">Assembly</a>, <a href="https://ai.stanford.edu/mech-search/multistep" rel="external nofollow noopener" target="_blank">Pick &amp; place</a>, <a href="https://roboturk.stanford.edu/realrobotdataset#tasks" rel="external nofollow noopener" target="_blank">Laundry Layout</a>, <a href="http://arxiv.org/abs/1909.09674" rel="external nofollow noopener" target="_blank">Assistive Teleoperation</a>, <a href="http://arxiv.org/abs/1903.01588" rel="external nofollow noopener" target="_blank">Mechanical Search</a> </li> <li>Surgical &amp; Healthcare: <a href="https://youtu.be/beVWB6NtAaA" rel="external nofollow noopener" target="_blank">Debridement</a>, <a href="https://youtu.be/z1ehShXFToc" rel="external nofollow noopener" target="_blank">Suturing</a>, <a href="https://youtu.be/l6gQg2VbGcc" rel="external nofollow noopener" target="_blank">Cutting</a>, <a href="https://www.youtube.com/watch?v=YiPq9t0tR3U" rel="external nofollow noopener" target="_blank">Extraction</a>, <a href="https://www.youtube.com/watch?v=Kk_wHiu8nGg&amp;feature=youtu.be" rel="external nofollow noopener" target="_blank">Radiotherapy</a> </li> <li>Legged Robotics: <a href="https://news.developer.nvidia.com/contact-adaptive-controller-locomotion" rel="external nofollow noopener" target="_blank">Contact Planning</a>, <a href="https://www.pair.toronto.edu/understanding-dr" rel="external nofollow noopener" target="_blank">Domain Randomization</a> </li> </ul> </article> </div> </div> <footer class="sticky-bottom mt-2" role="contentinfo"> <div class="container"> Â© Copyright 2025 PAIR Lab. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/al-folio/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/al-folio/assets/js/common.js?851dd38537fa237f7b0b46f2b4c3a94f"></script> <script defer src="/al-folio/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/al-folio/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/al-folio/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/al-folio/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/al-folio/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/al-folio/assets/js/search-data.js"></script> <script src="/al-folio/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>